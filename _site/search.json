[
  {
    "objectID": "articles.html",
    "href": "articles.html",
    "title": "Articles",
    "section": "",
    "text": "AGS4 Reference\n\n\n\nags\n\nags4\n\n\n\nA brief introduction to AGS.\n\n\n\n\n\nApr 14, 2025\n\n\nJules Blom\n\n\n\n\n\n\n\n\n\n\n\n\nBedrock ‚ù§Ô∏è Quarto\n\n\n\nquarto\n\n\n\nWhy I chose Quarto for building this website.\n\n\n\n\n\nAug 18, 2024\n\n\nJoost Gevaert\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to Bedrock\n\n\n\nnews\n\n\n\nAn introduction to Bedrock and Bedrock‚Äôs website.\n\n\n\n\n\nAug 17, 2024\n\n\nJoost Gevaert\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Under Construction üèóÔ∏è\n\n\n\nThis page of Bedrock‚Äôs website is still under construction. The content below comes from Quarto‚Äôs FAQ page. Most links on this page are broken.\n\n\n\nWhat can I use Quarto for?\nQuarto¬Æ is an open source scientific and technical publishing system built on Pandoc. You can weave together narrative text and code to produce elegantly formatted output as documents, web pages, blog posts, books and more.\n\n\nHow do I install Quarto?\nVisit the Quarto.org - Get Started page, which provides installation instructions for Windows, Mac OS, and Linux.\n\n\nIs Quarto free to use?\nYes! Quarto is open source. Quarto version 1.3 (and earlier) is licensed under the GNU GPL v2. Quarto version 1.4 is licensed under the MIT License.\n\n\nWhat output formats can Quarto create?\nThere are many output formats available in Quarto. This includes all of the built in Pandoc formats (e.g.¬†HTML, PDF, MS Word, Revealjs, ePub, etc.) as well as various ways to publish multiple documents (websites, blogs, and books). Learn more at Quarto Formats.¬†\n\n\nWhat editing tools can I use with Quarto?\nYou can use a wide variety of tools with Quarto. We have provided documentation for writing and editing Quarto documents in VSCode, JupyterLab, RStudio IDE, or any text editor. Visit the Get Started with Quarto page to install, and then choose your tool for a brief introductory guide.\n\n\nCan I use Jupyter notebooks with Quarto?\nYes! Quarto can render Jupyter notebooks and you can use Jupyter, JupyterLab or any other .ipynb notebook editor with Quarto. You can render existing .ipynb notebooks as-is with Quarto, but adding Quarto-specific output options or a YAML header can enhance the output. Visit theJupyterLab page for more information.\n\n\nWhat programming languages are supported in Quarto?\nThe principal languages supported by Quarto are Python, R, Julia, and Observable JavaScript. Integration with Jupyter also enables the use of many other languages.¬†\nEach Quarto document can be optionally processed by a computational engine (the engine can be manually specified or automatically detected based on the code chunks within). Current engines include Knitr (which is also used by R Markdown and supports a variety of languages including R, Python, and Julia, etc.) and Jupyter (which supports many languages including Python, Julia, and R). See the documentation on Engine Binding for additional details.\n\n\nWhat human languages are supported in Quarto?\nYou can write your Quarto documentation in your human language of choice. The lang document option is used to identify the main language of the document using IETF language tags (following the BCP 47 standard), such as en or en-GB.¬†\n\n\nCan I use Quarto to develop proprietary content?\nYes! The copyright on Quarto does not cover the original content that you generate using Quarto. Using Quarto to create original content does not place any restrictions, legally, on the license that you choose for the original content that you create, nor does it ‚Äúreach through‚Äù to affect software that you might be writing documentation for with Quarto.\n\n\nBut doesn‚Äôt the GPL cover exported HTML documents when they include styles or functionalities from Quarto?\nIt covers the styles or functionalities themselves. It does not cover your original content because your original content is not a derivative work of the Quarto styles or functionalities.\n\n\nHow can I share documents and have people comment on them?\nYou can publish Quarto content to various locations. See the user guides for publishing for details on using Quarto Pub, GitHub Pages, Netlify, Posit Connect, and other services with Quarto. Once documents are published you can use¬† hypothes.is, Utterances, or Giscus for commenting. Learn more in the documentation on commenting.\n\n\nCan I do collaborative editing with Quarto?\nThere is not yet anything specific for collaborative editing in Quarto. You can collaborate on .qmd files in the same way you currently do for any text or code files.¬†\nPosit Workbench allows for Project Sharing for interactive editing and collaboration on the same document.\n\n\nWhere can I publish Quarto websites?\nThere are a wide variety of ways to publish Quarto websites. Website content is by default written to the \\_site sub-directory (you can customize this using the output-dir option). Publishing is simply a matter of copying the output directory to a web server or web hosting service.\nThe publishing documentation describes several convenient options for Quarto website deployment including Posit Connect, Netlify, GitHub Pages, Firebase, Site44, and Amazon S3. We‚Äôll mostly defer to the documentation provided by those various services, but will note any Quarto website specific configuration required.\n\n\nDoes Posit Connect support Quarto?\nYes! You can publish Quarto content to Posit Connect v2021.08.0 or later. Quarto has to be enabled as documented in the Posit Connect admin guide. Connect‚Äôs user documentation refers to Quarto.org docs on how to publish from the RStudio IDE. To publish Python-based Quarto content, you can use the rsconnect-python CLI from various locations, including VSCode, JupyterLab or the terminal.\n\n\nWho are the developers of Quarto?\nDevelopment of Quarto is sponsored by Posit, PBC. The same core team works on both Quarto and R Markdown:\n\nCarlos Scheidegger (@cscheid)\nCharles Teague (@dragonstyle)\nChristophe Dervieux (@cderv)\nJ.J. Allaire (@jjallaire)\nYihui Xie (@yihui)\n\nHere is the full contributors list. Quarto is open source and we welcome contributions in our github repository as well! https://github.com/quarto-dev/quarto-cli.\n\n\nWhy the name Quarto?\nWe wanted to use a name that had meaning in the history of publishing and landed on Quarto, which is the format of a book or pamphlet produced from full sheets printed with eight pages of text, four to a side, then folded twice to produce four leaves. The earliest known European printed book is a Quarto, the Sibyllenbuch, believed to have been printed by Johannes Gutenberg in 1452‚Äì53.\n\n\nWhere can I report bugs or request features?\nThanks for finding something and sharing with us! You can file an issue in the Quarto repository https://github.com/quarto-dev/quarto-cli/issues.\n\n\nWhere can I ask questions and discuss using Quarto with others?\nThe best place to ask questions and see what questions other people have is in Quarto discussions (https://github.com/quarto-dev/quarto-cli/discussions)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bedrock",
    "section": "",
    "text": "Data Format\nRead\nWrite\n\n\n\n\nAGS 3\n‚úÖ\n‚ùå\n\n\nAGS 4\nSoon\npython-ags4\n\n\nExcel\n‚úÖ\n‚úÖ\n\n\nCSV\n‚úÖ\n‚úÖ\n\n\nJSON\n‚úÖ\n‚úÖ\n\n\nGeoJSON\n‚úÖ\n‚úÖ\n\n\n\nWhat do you need? DIGGS? NADAG? GEF? Something else?\nLet us know by creating an issue or starting a discussion üí≠\nAlso, if you have a project with publicly available GI data, please share that in a discussion, such that we can create a tutorial from it ü§©"
  },
  {
    "objectID": "index.html#read-write-ground-investigation-gi-data-in-different-formats",
    "href": "index.html#read-write-ground-investigation-gi-data-in-different-formats",
    "title": "Bedrock",
    "section": "",
    "text": "Data Format\nRead\nWrite\n\n\n\n\nAGS 3\n‚úÖ\n‚ùå\n\n\nAGS 4\nSoon\npython-ags4\n\n\nExcel\n‚úÖ\n‚úÖ\n\n\nCSV\n‚úÖ\n‚úÖ\n\n\nJSON\n‚úÖ\n‚úÖ\n\n\nGeoJSON\n‚úÖ\n‚úÖ\n\n\n\nWhat do you need? DIGGS? NADAG? GEF? Something else?\nLet us know by creating an issue or starting a discussion üí≠\nAlso, if you have a project with publicly available GI data, please share that in a discussion, such that we can create a tutorial from it ü§©"
  },
  {
    "objectID": "index.html#validate-your-gi-data",
    "href": "index.html#validate-your-gi-data",
    "title": "Bedrock",
    "section": "‚úÖ Validate your GI data",
    "text": "‚úÖ Validate your GI data\nbedrock-gi comes with data validation to make sure that you can combine Ground Investigation data from multiple files into a single GIS database with consistent relationships between GI locations, samples, in-situ measurements and lab tests.\nThis data validation mechanism (based on pandera) is easily extensible, giving you the power to add your own data validation criteria üí™"
  },
  {
    "objectID": "index.html#put-your-gi-data-from-multiple-files-into-a-single-3d-gis-database",
    "href": "index.html#put-your-gi-data-from-multiple-files-into-a-single-3d-gis-database",
    "title": "Bedrock",
    "section": "üó∫Ô∏è Put your GI data from multiple files into a single 3D GIS database",
    "text": "üó∫Ô∏è Put your GI data from multiple files into a single 3D GIS database\nFor example, you can take GI data from 100 AGS files and combine them into a single a GeoPackage (like a Shapefile, but then waaay better). Such a GeoPackage can then be loaded into ArcGIS, such that you can visualize your GI data in 3D, and perform analyses:"
  },
  {
    "objectID": "index.html#put-your-gi-data-into-speckle",
    "href": "index.html#put-your-gi-data-into-speckle",
    "title": "Bedrock",
    "section": "üü¶ Put your GI data into Speckle",
    "text": "üü¶ Put your GI data into Speckle\nOnce you have your GI data inside Speckle, it‚Äôs super easy to visualize GI data together with civil engineering designs:\n\n  Click here to go to the Kai Tak Speckle project from the left image\n\nMoreover, your GI data becomes available in all the software that Speckle has connectors for."
  },
  {
    "objectID": "index.html#free-and-open-source-software",
    "href": "index.html#free-and-open-source-software",
    "title": "Bedrock",
    "section": "üîì Free and Open Source Software",
    "text": "üîì Free and Open Source Software\nFree and Open Source Software (FOSS) gives you full access to the code, which means you can customize bedrock-gi to integrate with other tools and fit your workflows & project needs.\nAs the name implies, FOSS is free to use, so you‚Äôre not tied to expensive software licenses or locked into a specific software vendor ‚õìÔ∏è‚Äçüí•\nYou can give feedback and contribute, such that together we together can build the tools we‚Äôve always wanted and needed ü§ù"
  },
  {
    "objectID": "index.html#feedback",
    "href": "index.html#feedback",
    "title": "Bedrock",
    "section": "üí≠ Feedback",
    "text": "üí≠ Feedback\nGot some feedback, a great idea, running into problems when working with Bedrock or just want to ask some questions?\nPlease feel free to:\n\nopen an issue for feature requests or bug reports: bedrock-gi issues,\nstart a discussion in this GitHub repo: Bedrock discussions,\nor start a discussion on the Speckle community forum if that‚Äôs more appropriate: Speckle community forum\n\nAll feedback and engagement with the Bedrock community is welcome ü§ó"
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Bedrock",
    "section": "üë∑ Contributing",
    "text": "üë∑ Contributing\n\n\n\n\n\n\nCaution\n\n\n\nWait, please read this too!\n\n\nContributing isn‚Äôt scary üòÑ\nContributing isn‚Äôt just about writing code:\n\nUse Bedrock and provide feedback ü™≤\nShare how you use Bedrock üèóÔ∏è\nHelp each other out, e.g.¬†by replying to questions in the discussions or bedrock-gi issues ü§ù\nSpread the word about Bedrock ü§©\nDocumentation and tutorials üìÉ\nMost pages on the bedrock.engineer website can be edited, so if you see a spelling mistake or have a suggestion on how to explain something better, please smash that button! üñ±Ô∏èüí•\n\n\n\n\n\nIf you would like to contribute code, AWESOME! üíñ\nPlease create an issue for what you‚Äôd like to contribute. If you don‚Äôt know how to get started, please indicate this in your issue, and we‚Äôll help you out."
  },
  {
    "objectID": "docs/getting-started.html",
    "href": "docs/getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "In case you‚Äôre using uv, you can add bedrock-gi to your Python project and install it in your project‚Äôs virtual environment by running:\nuv add bedrock-gi\nI would highly recommend anyone to start using uv (Unified Virtual Environment Manager) if you‚Äôre not already doing so. Some of the advantages (Source: uv):\n\nüñ•Ô∏è uv Python projects will work on Windows, macOS and Linux.\nüêç uv installs and manages Python versions.\nüóÇÔ∏è uv provides comprehensive project management, with a universal lockfile. This means no more headaches about virtual environments (or having to explain what on earth a virtual env is), or people running different versions of Python or Python packages on the same project, causing errors and other problems.\nIn short, üöÄ uv is a single tool to replace pip, pip-tools, pipx, poetry, pyenv, virtualenv, conda and more‚Ä¶\n\nIt‚Äôs of course also possible to install bedrock-gi from PyPI (Python Packaging Index) using pip:\npip install bedrock-gi"
  },
  {
    "objectID": "docs/getting-started.html#installation",
    "href": "docs/getting-started.html#installation",
    "title": "Getting Started",
    "section": "",
    "text": "In case you‚Äôre using uv, you can add bedrock-gi to your Python project and install it in your project‚Äôs virtual environment by running:\nuv add bedrock-gi\nI would highly recommend anyone to start using uv (Unified Virtual Environment Manager) if you‚Äôre not already doing so. Some of the advantages (Source: uv):\n\nüñ•Ô∏è uv Python projects will work on Windows, macOS and Linux.\nüêç uv installs and manages Python versions.\nüóÇÔ∏è uv provides comprehensive project management, with a universal lockfile. This means no more headaches about virtual environments (or having to explain what on earth a virtual env is), or people running different versions of Python or Python packages on the same project, causing errors and other problems.\nIn short, üöÄ uv is a single tool to replace pip, pip-tools, pipx, poetry, pyenv, virtualenv, conda and more‚Ä¶\n\nIt‚Äôs of course also possible to install bedrock-gi from PyPI (Python Packaging Index) using pip:\npip install bedrock-gi"
  },
  {
    "objectID": "articles/2024-08-18-bedrock-loves-quarto/index.html",
    "href": "articles/2024-08-18-bedrock-loves-quarto/index.html",
    "title": "Bedrock ‚ù§Ô∏è Quarto",
    "section": "",
    "text": "Quarto makes it really easy to set up a smoothly working and beautiful website. It took me less than 3 days to set up Bedrock‚Äôs website with:\nQuarto makes it easy to implement many features that are essential for modern (docs) websites, see below ü§©. Building all these features from without handy tooling is, ‚Ä¶ daunting.\nOther tools I looked at:"
  },
  {
    "objectID": "articles/2024-08-18-bedrock-loves-quarto/index.html#quarto",
    "href": "articles/2024-08-18-bedrock-loves-quarto/index.html#quarto",
    "title": "Bedrock ‚ù§Ô∏è Quarto",
    "section": "Quarto?",
    "text": "Quarto?\n\nNice intro, but ‚Ä¶ Quarto?\n\n\nWhat\nHow: pandoc\nWhy\nWho: Posix + Community\nWhen"
  },
  {
    "objectID": "articles/2024-08-18-bedrock-loves-quarto/index.html#markdown",
    "href": "articles/2024-08-18-bedrock-loves-quarto/index.html#markdown",
    "title": "Bedrock ‚ù§Ô∏è Quarto",
    "section": "Markdown",
    "text": "Markdown\nMarkdown is an easy to read and write text format:\n\nIt‚Äôs plain text so works well with version control\nIt can be rendered into HTML (this website), PDF, Word (.docx), PowerPoint (.pptx) presentation and more‚Ä¶\nMany very useful basic features, see below.\nLearn more at: https://quarto.org/docs/authoring/\n\n\nEquations\nUse LaTeX to write equations: \\[\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n\\tag{1}\\]\n\n\nSource Code\nSee Static Code, Computed Code & Interactive Docs below.\n\n\nLists\nQuarto‚Äôs docs list some pretty awesome lists that I wasn‚Äôt aware of, and creative ways of using them. My highlight, definitions:\n\nterm or symbol, e.g.¬†\\(\\alpha\\)\n\ndefinition\n\n\n\n\nFootnotes\nFootnotes in a Quarto website get a hover preview ü§©1\n\n\n‚ÄúRaw Content‚Äù\nA somewhat cryptic way of saying that you can use this to to say that this is how you can embed other websites . For example:\n```{=html}\n&lt;iframe title=\"Kai Tak - Speckle\" src=\"https://app.speckle.systems/projects/013aaf06e7/models/0fa0287ba8,a739490298,c59c767566#embed=%7B%22isEnabled%22%3Atrue%7D\" width=\"100%\" height=\"500\" frameborder=\"0\"&gt;&lt;/iframe&gt;\n```\nembeds ‚¨áÔ∏è"
  },
  {
    "objectID": "articles/2024-08-18-bedrock-loves-quarto/index.html#static-code-computed-code-interactivity",
    "href": "articles/2024-08-18-bedrock-loves-quarto/index.html#static-code-computed-code-interactivity",
    "title": "Bedrock ‚ù§Ô∏è Quarto",
    "section": "Static Code, Computed Code & Interactivity",
    "text": "Static Code, Computed Code & Interactivity\nA Quarto Website project produces HTML documents (see _site directory) as output from the Quarto (.qmd), Markdown (.md), or Jupyter Notebook (.ipynb) files, which are then put together into a website with all the features a modern (docs) site needs by Quarto. Code blocks in these HTML documents comes in 2 types:\n\nStatic Code. Static code is not executed by Quarto when the website is generated, and can therefore not produce output such as figures. Static code blocks can be generated like this:\n  ```{.python}\n  print(\"This is a static code block. The code in this block will not be executed.\")\n  ```\nResult üëá\n\nprint(\"This is a static code block. The code in this block will not be executed.\")\n\nComputed Code. Computed code is executed by Quarto when the website it generated, and can therefore produce output such as figures. These figures can also be made interactive when you use a library such as plotly. Computed code blocks can be generated like this:\n  ```{python}\n  print(\"This is a computed code block. The code block will be executed.\")\n  ```\nResult üëá\n\n\n\nCode\nprint(\"This is a computed code block. The code block will be executed.\")\n\n\nThis is a computed code block. The code block will be executed.\n\n\nAs you can see, this is a bit tricky, because the difference between a code block being static ({.python}) and computed ({python}) is only a single ‚Äú.‚Äù.\nBelow a little more exciting example of a computed Python code block. Figure¬†1 actually comes from Quarto‚Äôs Get Started Guide.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure¬†1: A line plot on a polar axis\n\n\n\n\n\n\nCode Annotations\nQuarto also has beatiful code annotations:\n{\n  \"location\": {\n    \"attributes\": {},\n1    \"geometry\": \"Point / 3D LineString\",\n    \"children\": {}\n  }\n}\n\n1\n\nThe geometry of a borehole location is best represented by a ‚Äú3D LineString‚Äù. However, when visualizing the locations for which GI data is available on a 2D map, vertical lines vanish, in such cases using ‚ÄúPoint‚Äù geometry for the GI location is better."
  },
  {
    "objectID": "articles/2024-08-18-bedrock-loves-quarto/index.html#awesome-features-for-modern-websites",
    "href": "articles/2024-08-18-bedrock-loves-quarto/index.html#awesome-features-for-modern-websites",
    "title": "Bedrock ‚ù§Ô∏è Quarto",
    "section": "Awesome Features for Modern Websites",
    "text": "Awesome Features for Modern Websites\nSo, Markdown provides a great developer i.e.¬†contributor experience, and the Code & Interactivity features make Quarto documentation useful and engaging, but that doesn‚Äôt give you a good website yet. Therefore, this section highlights some of the awesome Quarto features that are essential for modern (docs) websites.\n\nWebsite Navigation\n\nNavBar\n\nLogo. Lacks Quarto docs though, so see the Quarto config of this website _quarto.yml on GitHub.\nHelp ‚ñº menu\nGitHub & Socials\nWebsite Search\n\nRight Sidebar\n\nSee ‚ÄúOn this Page‚Äù, and Table of Contents in the Quarto docs.\nPage specific GitHub Links\n\nLeft Sidebar\nRelevant for Bedrock‚Äôs Documentation, but not yet implemented. Look at Hybrid Navigation, meaning Sidebar Navigation for inside the Documentation part of the website only, while maintaining the NavBar.\n\n\n\n\n\n\n\nWarning¬†1: üêû No Search Placeholder\n\n\n\nWhen editing the search appearance when using a search textbox, the ‚ÄúSearch‚Äù placeholder is not showing up in the website.\n\n\n\n\nCross-References with Hover Preview\nThe way that cross-referencing is implemented in Quarto is very slick as well:\n\nCallout Blocks, e.g. Warning¬†1\nFigures:, e.g. Figure¬†1\nEquations, e.g. Equation¬†1\nThe list above only highlights some of the basics of cross-referencing with Quarto. Learn more at: Options, Div Syntaz, Custom Floats"
  },
  {
    "objectID": "articles/2024-08-18-bedrock-loves-quarto/index.html#promising-features",
    "href": "articles/2024-08-18-bedrock-loves-quarto/index.html#promising-features",
    "title": "Bedrock ‚ù§Ô∏è Quarto",
    "section": "Promising Features",
    "text": "Promising Features\nSeveral other Quarto features that I like and (might) want to make use of in the future:\n\nTabsets\nDark Mode\nDiagrams\nIn addition to Reference Popups, i.e.¬†hover previews for footnotes and cross-references, Quarto also has reference popups for citations.\nLinks to Source Notebooks, such that you can open up a docs page that‚Äôs based on a Jupyter Notebook directly in Google Colab (see Notebook Embed # View Options & Reference &gt; Formats &gt; HTML Options # Links notebook-view).\nOpen Graph config for richer sharing of links to specific pages of websites.\nquartodoc is a Python package for generating API reference documentation of a Python package with proper docstrings that is based on, and integrates with Quarto.\nCommenting such that you all can leave your thoughts right here üëá"
  },
  {
    "objectID": "articles/2024-08-18-bedrock-loves-quarto/index.html#footnotes",
    "href": "articles/2024-08-18-bedrock-loves-quarto/index.html#footnotes",
    "title": "Bedrock ‚ù§Ô∏è Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHey, that tickles ü§£‚Ü©Ô∏é"
  },
  {
    "objectID": "community.html",
    "href": "community.html",
    "title": "Community",
    "section": "",
    "text": "Under Construction üèóÔ∏è\n\n\n\nThis page of Bedrock‚Äôs website is still under construction.\n\n\nThe community of Bedrock has its home in the SWUNG (Software Underground) community.\nHowever, because Bedrock also has a strong link with Speckle - to make it possible to use ground investigation easily in all the software that are commonly used in the AEC (Architecture, Engineering & Construction) industry - you may want to post your questions on the Speckle community forum."
  },
  {
    "objectID": "articles/2024-08-17-welcome/index.html",
    "href": "articles/2024-08-17-welcome/index.html",
    "title": "Welcome to Bedrock",
    "section": "",
    "text": "Data Format\nRead\nWrite\n\n\n\n\nAGS 3\n‚úÖ\n‚ùå\n\n\nAGS 4\nSoon\npython-ags4\n\n\nExcel\n‚úÖ\n‚úÖ\n\n\nCSV\n‚úÖ\n‚úÖ\n\n\nJSON\n‚úÖ\n‚úÖ\n\n\nGeoJSON\n‚úÖ\n‚úÖ\n\n\n\nWhat do you need? DIGGS? NADAG? GEF? Something else?\nLet us know by creating an issue or starting a discussion üí≠\nAlso, if you have a project with publicly available GI data, please share that in a discussion, such that we can create a tutorial from it ü§©"
  },
  {
    "objectID": "articles/2024-08-17-welcome/index.html#read-write-ground-investigation-gi-data-in-different-formats",
    "href": "articles/2024-08-17-welcome/index.html#read-write-ground-investigation-gi-data-in-different-formats",
    "title": "Welcome to Bedrock",
    "section": "",
    "text": "Data Format\nRead\nWrite\n\n\n\n\nAGS 3\n‚úÖ\n‚ùå\n\n\nAGS 4\nSoon\npython-ags4\n\n\nExcel\n‚úÖ\n‚úÖ\n\n\nCSV\n‚úÖ\n‚úÖ\n\n\nJSON\n‚úÖ\n‚úÖ\n\n\nGeoJSON\n‚úÖ\n‚úÖ\n\n\n\nWhat do you need? DIGGS? NADAG? GEF? Something else?\nLet us know by creating an issue or starting a discussion üí≠\nAlso, if you have a project with publicly available GI data, please share that in a discussion, such that we can create a tutorial from it ü§©"
  },
  {
    "objectID": "articles/2024-08-17-welcome/index.html#validate-your-gi-data",
    "href": "articles/2024-08-17-welcome/index.html#validate-your-gi-data",
    "title": "Welcome to Bedrock",
    "section": "‚úÖ Validate your GI data",
    "text": "‚úÖ Validate your GI data\nbedrock-gi comes with data validation to make sure that you can combine Ground Investigation data from multiple files into a single GIS database with consistent relationships between GI locations, samples, in-situ measurements and lab tests.\nThis data validation mechanism (based on pandera) is easily extensible, giving you the power to add your own data validation criteria üí™"
  },
  {
    "objectID": "articles/2024-08-17-welcome/index.html#put-your-gi-data-from-multiple-files-into-a-single-3d-gis-database",
    "href": "articles/2024-08-17-welcome/index.html#put-your-gi-data-from-multiple-files-into-a-single-3d-gis-database",
    "title": "Welcome to Bedrock",
    "section": "üó∫Ô∏è Put your GI data from multiple files into a single 3D GIS database",
    "text": "üó∫Ô∏è Put your GI data from multiple files into a single 3D GIS database\nFor example, you can take GI data from 100 AGS files and combine them into a single a GeoPackage (like a Shapefile, but then waaay better). Such a GeoPackage can then be loaded into ArcGIS, such that you can visualize your GI data in 3D, and perform analyses:"
  },
  {
    "objectID": "articles/2024-08-17-welcome/index.html#put-your-gi-data-into-speckle",
    "href": "articles/2024-08-17-welcome/index.html#put-your-gi-data-into-speckle",
    "title": "Welcome to Bedrock",
    "section": "üü¶ Put your GI data into Speckle",
    "text": "üü¶ Put your GI data into Speckle\nOnce you have your GI data inside Speckle, it‚Äôs super easy to visualize GI data together with civil engineering designs:\n\n  Click here to go to the Kai Tak Speckle project from the left image\n\nMoreover, your GI data becomes available in all the software that Speckle has connectors for."
  },
  {
    "objectID": "articles/2024-08-17-welcome/index.html#free-and-open-source-software",
    "href": "articles/2024-08-17-welcome/index.html#free-and-open-source-software",
    "title": "Welcome to Bedrock",
    "section": "üîì Free and Open Source Software",
    "text": "üîì Free and Open Source Software\nFree and Open Source Software (FOSS) gives you full access to the code, which means you can customize bedrock-gi to integrate with other tools and fit your workflows & project needs.\nAs the name implies, FOSS is free to use, so you‚Äôre not tied to expensive software licenses or locked into a specific software vendor ‚õìÔ∏è‚Äçüí•\nYou can give feedback and contribute, such that together we together can build the tools we‚Äôve always wanted and needed ü§ù"
  },
  {
    "objectID": "articles/2024-08-17-welcome/index.html#feedback",
    "href": "articles/2024-08-17-welcome/index.html#feedback",
    "title": "Welcome to Bedrock",
    "section": "üí≠ Feedback",
    "text": "üí≠ Feedback\nGot some feedback, a great idea, running into problems when working with Bedrock or just want to ask some questions?\nPlease feel free to:\n\nopen an issue for feature requests or bug reports: bedrock-gi issues,\nstart a discussion in this GitHub repo: Bedrock discussions,\nor start a discussion on the Speckle community forum if that‚Äôs more appropriate: Speckle community forum\n\nAll feedback and engagement with the Bedrock community is welcome ü§ó"
  },
  {
    "objectID": "articles/2024-08-17-welcome/index.html#contributing",
    "href": "articles/2024-08-17-welcome/index.html#contributing",
    "title": "Welcome to Bedrock",
    "section": "üë∑ Contributing",
    "text": "üë∑ Contributing\n\n\n\n\n\n\nCaution\n\n\n\nWait, please read this too!\n\n\nContributing isn‚Äôt scary üòÑ\nContributing isn‚Äôt just about writing code:\n\nUse Bedrock and provide feedback ü™≤\nShare how you use Bedrock üèóÔ∏è\nHelp each other out, e.g.¬†by replying to questions in the discussions or bedrock-gi issues ü§ù\nSpread the word about Bedrock ü§©\nDocumentation and tutorials üìÉ\nMost pages on the bedrock.engineer website can be edited, so if you see a spelling mistake or have a suggestion on how to explain something better, please smash that button! üñ±Ô∏èüí•\n\n\n\n\n\nIf you would like to contribute code, AWESOME! üíñ\nPlease create an issue for what you‚Äôd like to contribute. If you don‚Äôt know how to get started, please indicate this in your issue, and we‚Äôll help you out."
  },
  {
    "objectID": "articles/2025-04-14-ags/index.html",
    "href": "articles/2025-04-14-ags/index.html",
    "title": "AGS4 Reference",
    "section": "",
    "text": "AGS4 is a standardized text file format specifically designed for exchanging geotechnical information between different software systems used in geotechnical engineering. It organizes borehole logs, laboratory test results, and field measurements into structured data tables with validation rules to ensure consistent data quality across the geotechnical industry."
  },
  {
    "objectID": "articles/2025-04-14-ags/index.html#groups",
    "href": "articles/2025-04-14-ags/index.html#groups",
    "title": "AGS4 Reference",
    "section": "Groups",
    "text": "Groups\nIn the AGS4 format, Groups are organizational containers that structure geotechnical data. Each Group represents a specific aspect of geotechnical investigation, for example, project information (PROJ), location details (LOCA), sample information (SAMP), or specific test types like Standard Penetration Tests (ISPT).\nAGS4 Groups are organised in a hierarchical manner. Each sample (SAMP) belongs to a location (LOCA). Each location belongs to a project (PROJ).\nHere‚Äôs a visual of the hierarchy of groups commonly found in an AGS4 file.\n\nPROJProject information\n\nPROJ\n\nLOCALocation details\n\nPROJ/LOCA\n\nABBRAbbreviation Definitions\n\nPROJ/ABBR\n\nTRANData File Transmission Information / Data Status\n\nPROJ/TRAN\n\nTYPEDefinition of Data Types\n\nPROJ/TYPE\n\nUNITDefinition of Units\n\nPROJ/UNIT\n\nSAMPSample information\n\nPROJ/LOCA/SAMP\n\nIPRGInsitu permeability\n\nPROJ/LOCA/IPRG\n\nGEOLGeological descriptions\n\nPROJ/LOCA/GEOL\n\nBKFLBackfill details\n\nPROJ/LOCA/BKFL\n\nISPTStandard Penetration Test\n\nPROJ/LOCA/ISPT\n\nGRAGParticle size distribution analysis\n\nPROJ/LOCA/SAMP/GRAG\n\nLNMCWater content\n\nPROJ/LOCA/SAMP/LNMC\n\nIPRTInsitu permeability data\n\nPROJ/LOCA/IPRG/IPRT\n\nGRATParticle size distribution analysis data\n\nPROJ/LOCA/SAMP/GRAG/GRAT\n\n\n\n\n\nAll Groups Hierarchy Tree\n\nWhile AGS defines a load of groups, not all of them are used in every project. For reference, here is the full hierarchy tree of all groups.\n\nAGS4 file-\n\nAGS4 file\n\nPROJProject Information\n\nAGS4 file/PROJ\n\nABBRAbbreviation Definitions\n\nAGS4 file/ABBR\n\nDICTUser Defined Groups and Headings\n\nAGS4 file/DICT\n\nFILEAssociated Files\n\nAGS4 file/FILE\n\nTRANData File Transmission Information / Data Status\n\nAGS4 file/TRAN\n\nTYPEDefinition of Data Types\n\nAGS4 file/TYPE\n\nUNITDefinition of Units\n\nAGS4 file/UNIT\n\nLOCALocation Details\n\nAGS4 file/PROJ/LOCA\n\nSAMPSample Information\n\nAGS4 file/PROJ/LOCA/SAMP\n\nBKFLExploratory Hole Backfill Details\n\nAGS4 file/PROJ/LOCA/BKFL\n\nCDIACasing Diameter by Depth\n\nAGS4 file/PROJ/LOCA/CDIA\n\nCHISChiselling Details\n\nAGS4 file/PROJ/LOCA/CHIS\n\nCORECoring Information\n\nAGS4 file/PROJ/LOCA/CORE\n\nDCPGDynamic Cone Penetrometer Tests - General\n\nAGS4 file/PROJ/LOCA/DCPG\n\nDETLStratum Detail Descriptions\n\nAGS4 file/PROJ/LOCA/DETL\n\nDISCDiscontinuity Data\n\nAGS4 file/PROJ/LOCA/DISC\n\nDLOGDriller Geological Description\n\nAGS4 file/PROJ/LOCA/DLOG\n\nDOBSDrilling/Advancement Observations & Parameters\n\nAGS4 file/PROJ/LOCA/DOBS\n\nDPRGDynamic Probe Tests - General\n\nAGS4 file/PROJ/LOCA/DPRG\n\nDREMDepth Related Remarks\n\nAGS4 file/PROJ/LOCA/DREM\n\nFGHGField Geohydraulic Testing - General\n\nAGS4 file/PROJ/LOCA/FGHG\n\nFLSHDrilling Flush Details\n\nAGS4 file/PROJ/LOCA/FLSH\n\nFRACFracture Spacing\n\nAGS4 file/PROJ/LOCA/FRAC\n\nGEOLField Geological Descriptions\n\nAGS4 file/PROJ/LOCA/GEOL\n\nHDIAHole Diameter by Depth\n\nAGS4 file/PROJ/LOCA/HDIA\n\nHDPHDepth Related Exploratory Hole Information\n\nAGS4 file/PROJ/LOCA/HDPH\n\nHORNExploratory Hole Orientation and Inclination\n\nAGS4 file/PROJ/LOCA/HORN\n\nICBRIn Situ California Bearing Ratio Tests\n\nAGS4 file/PROJ/LOCA/ICBR\n\nIDENIn Situ Density Tests\n\nAGS4 file/PROJ/LOCA/IDEN\n\nIFIDOn Site Volatile Headspace Testing Using Flame Ionisation Detector\n\nAGS4 file/PROJ/LOCA/IFID\n\nIPENIn Situ Hand Penetrometer Tests\n\nAGS4 file/PROJ/LOCA/IPEN\n\nIPIDOn Site Volatile Headspace Testing by Photo Ionisation Detector\n\nAGS4 file/PROJ/LOCA/IPID\n\nIPRGIn Situ Permeability Tests - General\n\nAGS4 file/PROJ/LOCA/IPRG\n\nIRDXIn Situ Redox Tests\n\nAGS4 file/PROJ/LOCA/IRDX\n\nIRESIn Situ Resistivity Tests\n\nAGS4 file/PROJ/LOCA/IRES\n\nISAGSoakaway Tests - General\n\nAGS4 file/PROJ/LOCA/ISAG\n\nISPTStandard Penetration Test Results\n\nAGS4 file/PROJ/LOCA/ISPT\n\nIVANIn Situ Vane Tests\n\nAGS4 file/PROJ/LOCA/IVAN\n\nAAVTAggregate Abrasion Tests\n\nAGS4 file/PROJ/LOCA/SAMP/AAVT\n\nACVTAggregate Crushing Value Tests\n\nAGS4 file/PROJ/LOCA/SAMP/ACVT\n\nAELO -\n\nAGS4 file/PROJ/LOCA/SAMP/AELO\n\nAFLKAggregate Flakiness Tests\n\nAGS4 file/PROJ/LOCA/SAMP/AFLK\n\nAIVTAggregate Impact Value Tests\n\nAGS4 file/PROJ/LOCA/SAMP/AIVT\n\nALOSLos Angeles Abrasion Tests\n\nAGS4 file/PROJ/LOCA/SAMP/ALOS\n\nAPSVAggregate Polished Stone Tests\n\nAGS4 file/PROJ/LOCA/SAMP/APSV\n\nARTWAggregate Determination of the Resistance to Wear (micro-Deval)\n\nAGS4 file/PROJ/LOCA/SAMP/ARTW\n\nASDISlake Durability Index Tests\n\nAGS4 file/PROJ/LOCA/SAMP/ASDI\n\nASNSAggregate Soundness Tests\n\nAGS4 file/PROJ/LOCA/SAMP/ASNS\n\nAWADAggregate Water Absorption Tests\n\nAGS4 file/PROJ/LOCA/SAMP/AWAD\n\nCBRGCalifornia Bearing Ratio Tests - General\n\nAGS4 file/PROJ/LOCA/SAMP/CBRG\n\nCHOCChain of Custody Information\n\nAGS4 file/PROJ/LOCA/SAMP/CHOC\n\nCMPGCompaction Tests - General\n\nAGS4 file/PROJ/LOCA/SAMP/CMPG\n\nCONGConsolidation Tests - General\n\nAGS4 file/PROJ/LOCA/SAMP/CONG\n\nCTRGCyclic Triaxial Test - General\n\nAGS4 file/PROJ/LOCA/SAMP/CTRG\n\nECTNSample Container Details\n\nAGS4 file/PROJ/LOCA/SAMP/ECTN\n\nELRGEnvironmental Laboratory Reporting\n\nAGS4 file/PROJ/LOCA/SAMP/ELRG\n\nERESEnvironmental Contaminant Testing\n\nAGS4 file/PROJ/LOCA/SAMP/ERES\n\nESCGEffective Stress Consolidation Tests - General\n\nAGS4 file/PROJ/LOCA/SAMP/ESCG\n\nFRSTFrost Susceptibility Tests\n\nAGS4 file/PROJ/LOCA/SAMP/FRST\n\nGCHMGeotechnical Chemistry Testing\n\nAGS4 file/PROJ/LOCA/SAMP/GCHM\n\nGRAGParticle Size Distribution Analysis - General\n\nAGS4 file/PROJ/LOCA/SAMP/GRAG\n\nDCPTDynamic Cone Penetrometer Tests - Data\n\nAGS4 file/PROJ/LOCA/DCPG/DCPT\n\nDPRBDynamic Probe Tests - Data\n\nAGS4 file/PROJ/LOCA/DPRG/DPRB\n\nFGHIField Geohydraulic Testing - Instrumentation Details\n\nAGS4 file/PROJ/LOCA/FGHG/FGHI\n\nFGHSField Geohydraulic Testing - Test Results (per stage)\n\nAGS4 file/PROJ/LOCA/FGHG/FGHS\n\nIPRTIn Situ Permeability Tests - Data\n\nAGS4 file/PROJ/LOCA/IPRG/IPRT\n\nISATSoakaway Tests - Data\n\nAGS4 file/PROJ/LOCA/ISAG/ISAT\n\nCBRTCalifornia Bearing Ratio Tests - Data\n\nAGS4 file/PROJ/LOCA/SAMP/CBRG/CBRT\n\nCMPTCompaction Tests - Data\n\nAGS4 file/PROJ/LOCA/SAMP/CMPG/CMPT\n\nCONSConsolidation Tests - Data\n\nAGS4 file/PROJ/LOCA/SAMP/CONG/CONS\n\nCTRCCyclic Triaxial Tests - Consolidation\n\nAGS4 file/PROJ/LOCA/SAMP/CTRG/CTRC\n\nCTRSCyclic Triaxial Test - Saturation\n\nAGS4 file/PROJ/LOCA/SAMP/CTRG/CTRS\n\nESCTEffective Stress Consolidation Tests - Data\n\nAGS4 file/PROJ/LOCA/SAMP/ESCG/ESCT\n\nGRATParticle Size Distribution Analysis - Data\n\nAGS4 file/PROJ/LOCA/SAMP/GRAG/GRAT\n\nFGHTField Geohydraulic Testing - Data\n\nAGS4 file/PROJ/LOCA/FGHG/FGHI/FGHT\n\nCTRPCyclic Triaxial Test - Derived Parameters\n\nAGS4 file/PROJ/LOCA/SAMP/CTRG/CTRC/CTRP\n\nCTRDCyclic Triaxial Tests - Data\n\nAGS4 file/PROJ/LOCA/SAMP/CTRG/CTRC/CTRP/CTRD\n\n\n\n\n\n\nCode\nviewof groupSearch = Inputs.search(ags4, {\n  placeholder: \"Search groups...\"\n})\n\n\n\n\n\n\n\n\n\nCode\nviewof groupTable = Inputs.table(groupSearch, {\n  format: { headings: (d) =&gt; d.map((h) =&gt; h.heading).join(\", \") },\n  multiple: false,\n  layout: \"auto\"\n})\n\n\n\n\n\n\n\n\n\nCode\nags4 = FileAttachment(\"ags4_data_dictionary.json\").json()"
  },
  {
    "objectID": "articles/2025-04-14-ags/index.html#headings",
    "href": "articles/2025-04-14-ags/index.html#headings",
    "title": "AGS4 Reference",
    "section": "Headings",
    "text": "Headings\nHeadings are the specific data fields (i.e.¬†the columns) within each group that define individual data items. Each heading represents a specific piece of information that can be recorded during geotechnical investigations, such as sample depth, moisture content, or test result values\nHeadings follow a standardized naming pattern, typically beginning with the group name as a prefix (e.g., ‚ÄúPROJ_ID‚Äù for project identifier in the PROJ group). Some headings are marked as required (*R or R), indicating that they must be populated in a valid AGS file to maintain data integrity. Headings include additional information like units of measurement, descriptions, and example values to help users understand their purpose.\n\n\nCode\ngroupTable ? md`### ${groupTable.group_name}\\n${groupTable.group_description}` : md`### Select a group in the table above to view its headings.`\n\n\n\n\n\n\n\n\n\nCode\ngroupTable\n  ? Inputs.table(groupTable.headings, {\n      layout: \"auto\",\n      columns: [\"heading\", \"description\", \"type\", \"unit\", \"example\"],\n      format: {\n        type: (d) =&gt; (d in types ? types[d] : d),\n        status: (d) =&gt; {\n          switch (d) {\n            case \"*\":\n              return \"KEY\";\n            case \"R\":\n              return \"Required\";\n            default:\n              return \"\";\n          }\n        }\n      }\n    })\n  : null\n\n\n\n\n\n\n\n\n\nCode\ntypes = ({\n  ...Object.fromEntries(\n    Array.from({ length: 5 }, (_, i) =&gt; i).map((i) =&gt; [\n      `${i}DP`,\n      `Value with ${i} required decimal places`\n    ])\n  ),\n  ...Object.fromEntries(\n    Array.from({ length: 4 }, (_, i) =&gt; i).map((i) =&gt; [\n      `${i}SF`,\n      `${i} sign. figures`\n    ])\n  ),\n  DT: \"Datetime\",\n  T: \"Time elapsed\",\n  X: \"Text\",\n  YN: \"Yes/no\",\n  ID: \"Unique Identifier\",\n  XN: \"Text/numeric\",\n  PA: \"Text listed in ABBR Group\",\n  PU: \"Text listed in UNIT Group\",\n  U: \"Value with a variable format\"\n})"
  },
  {
    "objectID": "docs/index.html",
    "href": "docs/index.html",
    "title": "Documentation",
    "section": "",
    "text": "Definition of Bedrock\nIn an abstract sense, the main principles on which something is based. [1]\nIn the real world, the bedrock is the hard area of rock in the ground that holds up the loose soil above. [1]\nIn many civil engineering projects, the identification of the bedrock through digging, drilling or geophysical methods is an important task, which greatly influences (foundation) design. [2]\nSources: [1] Bedrock | Cambridge Dictionary, [2] Bedrock | Wikipedia\n\nBedrock, this open source software project, forms the foundation for for ground investigation data, subsurface modelling and Geo-BIM.\nWith Bedrock you can get your data from any Ground Investigation data format into a GIS database üó∫Ô∏è, from a GIS database into Speckle üü¶, and from Speckle into all the software we work with in the AEC industry üèóÔ∏è.\nThe purpose of Bedrock is NOT to become THE standard for geotechnical data, because we don‚Äôt need 15 instead of 14 competing standards:\n\n  Source: https://xkcd.com/927\n\nFor example, us geotechnical engineers who are used to working with AGS data know that the ‚ÄúISPT group‚Äù is a table that describes an In-Situ Standard Penetration Test and we know what headings, i.e.¬†columns that AGS group, i.e.¬†table has. Therefore, Bedrock doesn‚Äôt change that the naming of those columns. Bedrock just makes sure that the data is structured in a sensible way, such that Ground Investigation data from multiple sources can be converted into a GIS database.\nA GIS database with Ground Investigation data contains tables that describe the Ground Investigation 'Project', the 'Location's where GI data was collected, the 'Sample's and 'InSitu' measurements taken at these 'Location's, and the 'Lab' tests that were performed on the collected 'Sample's.\nThe 'Project', 'Location', 'Sample', 'InSitu' measurement and 'Lab' test tables are related to each other: each lab test belongs to a sample, which belongs to a GI location, which belongs to a project. These relationships can be visualized in a hierarchy like this:\n'Project'\n ‚îî‚îÄ‚îÄ‚îÄ'Location'\n     ‚îú‚îÄ‚îÄ‚îÄ'InSitu'\n     ‚îî‚îÄ‚îÄ‚îÄ'Sample'\n          ‚îî‚îÄ‚îÄ‚îÄ'Lab'\nThese relationships are represented in the database tables with so-called ‚Äúforeign keys‚Äù. For example, the results of an Atterberg Limits Lab test, i.e.¬†Liquid Limit and Plastic Limit tests, that originated from an AGS file would be in stored in the 'Lab_LLPL' table. Each row in this table represents the Atterberg Limit test results performed on a specific sample. Each row knows to which project, GI location and sample it belongs through its project_uid, location_uid and sample_uid respectively.\nThis relational database (linked tables) with Ground Investigation data becomes a GIS database by assigning a (3D) GIS geometry to each of the rows in each of the database tables (except for the 'Project' table)."
  },
  {
    "objectID": "docs/Tutorials/ags3_to_gis_and_speckle.html",
    "href": "docs/Tutorials/ags3_to_gis_and_speckle.html",
    "title": "Kai Tak",
    "section": "",
    "text": "Kai Tak is a neighborhood in Kowloon, Hong Kong. One of the highlights of Kai Tak used to be it‚Äôs airport, which holds a special place in aviation history due to its unique and challenging approach, which involved pilots making a steep descent over a densely populated area while making a sharp turn at the same time and then landing on a single runway that jutted out into Victoria Harbor. Landing at Kai Tak Airport | YouTube\nIn 1998 the new Hong Kong International Airport opened, and operations at Kai Tak Airport were ceased. After the closure, the former Kai Tak Airport and surrounding neighborhood underwent a massive redevelopment project to transform it into a new residential and commercial district, which is still continuing today.\nHave a look at the Kai Tak Speckle Project to get an idea what Kai Tak looks like now. (Developents are going fast, so Google Earth 3D is a bit outdated.)\nGround Investigation Data for Hong Kong can be found here:\nGEO Data for Public Use\n\n\nCode\nimport bedrock.gi as brgi\nimport requests\n\n\n\n\nCode\ndata_root = \"https://github.com/bedrock-gi/bedrock-web/raw/main/public/gi-data/kaitak\"\nreport_number = 31241\nfile_name = \"GE9908.7.ags\"\ndata_url = f\"{data_root}/{str(report_number)}/{file_name}\"\n\nresponse = requests.get(data_url)\n\nif response.status_code == 200:\n    ags3_str = response.content.decode(\"utf-8\")\nelse:\n    print(f\"Failed to retrieve data: {response.status_code}\")\n\n\n\n\nCode\ndata_url\n\n\n'https://github.com/bedrock-gi/bedrock-web/raw/main/public/gi-data/kaitak/31241/GE9908.7.ags'\n\n\n\n\nCode\nags3_dfs = brgi.ags3_to_dfs(ags3_str)\n\n\nNo data was found on line 3. Last Group: PROJ\nNo data was found on line 43. Last Group: HOLE\nNo data was found on line 44. Last Group: HOLE\nNo data was found on line 45. Last Group: HOLE\nNo data was found on line 84. Last Group: PTIM\nNo data was found on line 125. Last Group: SAMP\nNo data was found on line 194. Last Group: GEOL\nNo data was found on line 195. Last Group: GEOL\nNo data was found on line 196. Last Group: GEOL\nNo data was found on line 197. Last Group: GEOL\nNo data was found on line 198. Last Group: GEOL\nNo data was found on line 199. Last Group: GEOL\n\n\n\n\nCode\nags3_dfs.keys()\n\n\ndict_keys(['PROJ', 'HOLE', 'PTIM', 'SAMP', 'GEOL'])\n\n\n\n\nCode\nags3_dfs[\"HOLE\"].columns\n\n\nIndex(['HOLE_ID', 'HOLE_TYPE', 'HOLE_NATE', 'HOLE_NATN', 'HOLE_GL',\n       'HOLE_FDEP', 'HOLE_STAR', 'HOLE_LOG', 'HOLE_REM', 'HOLE_LOCX',\n       'HOLE_LOCY', 'HOLE_LOCZ', 'HOLE_ENDD', 'HOLE_BACD', 'HOLE_CREW',\n       'HOLE_ORNT', 'HOLE_INCL', 'HOLE_EXC', 'HOLE_SHOR\",', 'HOLE_STAB',\n       'HOLE_DIMW', 'HOLE_DIML'],\n      dtype='object')\n\n\n\n\nCode\nags3_dfs[\"HOLE\"]\n\n\n\n\n\n\n\n\n\nHOLE_ID\nHOLE_TYPE\nHOLE_NATE\nHOLE_NATN\nHOLE_GL\nHOLE_FDEP\nHOLE_STAR\nHOLE_LOG\nHOLE_REM\nHOLE_LOCX\n...\nHOLE_ENDD\nHOLE_BACD\nHOLE_CREW\nHOLE_ORNT\nHOLE_INCL\nHOLE_EXC\nHOLE_SHOR\",\nHOLE_STAB\nHOLE_DIMW\nHOLE_DIML\n\n\n\n\n0\nAC1\nVC\n838804.86\n820146.79\n-4.40\n6.00\n16/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.10m to 1.10m...\n\n...\n16/06/2000\n16/06/2000\n\n000\n90\nG35\n\n\n\n\n\n\n1\nAC2(B)\nVC\n838924.24\n819940.24\n-2.00\n6.00\n17/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.00m to 1.00m...\n\n...\n17/06/2000\n17/06/2000\n\n000\n90\nG35\n\n\n\n\n\n\n2\nAC3\nVC\n839082.41\n819958.33\n-4.80\n6.00\n17/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.20m to 1.20m...\n\n...\n17/06/2000\n17/06/2000\n\n000\n90\nG35\n\n\n\n\n\n\n3\nAC4(A)\nVC\n839202.72\n819766.02\n-4.75\n6.00\n19/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.25m to 1.25m...\n\n...\n19/06/2000\n19/06/2000\n\n000\n90\nG35\n\n\n\n\n\n\n4\nAC5\nVC\n839315.26\n819565.15\n-3.20\n11.00\n16/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.00m to 0.75m...\n\n...\n16/06/2000\n16/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n5\nAC6\nVC\n839478.85\n819577.05\n-6.10\n5.00\n17/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.25m to 0.85m...\n\n...\n17/06/2000\n17/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n6\nAC7(B)\nVC\n839599.62\n819393.66\n-6.10\n5.00\n17/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.65m to 1.45m...\n\n...\n17/06/2000\n17/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n7\nKB1\nVC\n837972.72\n818966.22\n-7.90\n6.00\n21/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.00m to 0.90m...\n\n...\n21/06/2000\n21/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n8\nKB2(A)\nVC\n838048.56\n819357.17\n-6.80\n5.50\n21/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.00m to 0.74m...\n\n...\n21/06/2000\n21/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n9\nKB3\nVC\n838045.89\n819656.72\n-6.70\n4.00\n21/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.05m to 0.51m...\n\n...\n21/06/2000\n21/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n10\nKB4\nVC\n838450.29\n819374.58\n-7.10\n4.50\n22/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.10m to 0.63m...\n\n...\n22/06/2000\n22/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n11\nKB5(A)\nVC\n838271.87\n819591.33\n-6.00\n6.00\n22/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.10m to 0.43m...\n\n...\n22/06/2000\n22/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n12\nKB6(A)\nVC\n838350.72\n819973.01\n-1.90\n6.00\n20/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.10m to 0.70m...\n\n...\n20/06/2000\n20/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n13\nKB7\nVC\n838659.40\n819678.09\n-4.20\n6.00\n20/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.00m to 0.55m...\n\n...\n20/06/2000\n20/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n14\nKT1\nVC\n839914.66\n819393.56\n-5.75\n6.00\n19/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.30m to 0.60m...\n\n...\n19/06/2000\n19/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n15\nKT2\nVC\n840073.08\n819241.19\n-5.60\n6.00\n19/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.35m to 0.92m...\n\n...\n19/06/2000\n19/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n16\nKT3\nVC\n841064.83\n818296.58\n-10.20\n4.50\n20/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.10m to 1.10m...\n\n...\n20/06/2000\n20/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n17\nKT4\nVC\n840912.49\n818138.16\n-8.00\n6.00\n19/06/2000\nMY LEE\n1. Sub-samples were taken at A) 0.00m to 1.00m...\n\n...\n19/06/2000\n19/06/2000\n\n000\n90\nDM2\n\n\n\n\n\n\n\n\n18 rows √ó 22 columns"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, I‚Äôm Joost Gevaert üëã\nI studied geotechnical engineering and applied geophysics and then worked for Arup for 4 years as a geotechnical engineer an computational designer.\nDuring my time at Arup I worked a lot on bringing computational design into the world of geotechnical engineering, and on bridging the gaps between geotechnical engineering and structural engineering.\nBedrock is the Free and Open Source Software (FOSS) that I wish existed when I worked as a geotechnical engineer at Arup.\n\nComputational design is a field that involves the use of computer algorithms, simulations, and data analysis to support and enhance the design process. It enables designers to explore vast design spaces, to find solutions to complex design problems, and to make informed decisions based on data-driven insights.\nSource: Computational design | Arup"
  },
  {
    "objectID": "about.html#joost-gevaert",
    "href": "about.html#joost-gevaert",
    "title": "About",
    "section": "",
    "text": "Hi, I‚Äôm Joost Gevaert üëã\nI studied geotechnical engineering and applied geophysics and then worked for Arup for 4 years as a geotechnical engineer an computational designer.\nDuring my time at Arup I worked a lot on bringing computational design into the world of geotechnical engineering, and on bridging the gaps between geotechnical engineering and structural engineering.\nBedrock is the Free and Open Source Software (FOSS) that I wish existed when I worked as a geotechnical engineer at Arup.\n\nComputational design is a field that involves the use of computer algorithms, simulations, and data analysis to support and enhance the design process. It enables designers to explore vast design spaces, to find solutions to complex design problems, and to make informed decisions based on data-driven insights.\nSource: Computational design | Arup"
  },
  {
    "objectID": "about.html#jules-blom",
    "href": "about.html#jules-blom",
    "title": "About",
    "section": "Jules Blom",
    "text": "Jules Blom\nHi, my name is Jules. I studied Applied Geoscience (Petroleum Engineering Reservoir Geology) but frustration with technical software led me to learn to code and as a result, I mostly worked in software development.\nOver the past 5 years, I‚Äôve worked on data-rich applications across various domains, specifically frontend development. My primary interest is figuring out how to build tools for more thoughtful display and processing of technical information, geoscience in particular."
  },
  {
    "objectID": "sandbox/ags_data_dict_from_pdf_to_json.html",
    "href": "sandbox/ags_data_dict_from_pdf_to_json.html",
    "title": "Extract Data from .pdf with ChatGPT",
    "section": "",
    "text": "Code\nimport json\nimport os\n\nimport pandas as pd\nimport pdfplumber\n\nos.getcwd()\n\n\n'c:\\\\Users\\\\joost\\\\ReposWindows\\\\bedrock-web\\\\sandbox'\nUpload the AGS3-3-1-2005.pdf\nThen use a prompt like this:\nIt might require a bit of chatting with ChatGPT before you get a proper table in your chat. Once you do, you can copy-paste it to a .tsv file. A .tsv file is a Tab Separated Value file instead of CSV - Comma Separated Value file, which is what you get when you copy the table from ChatGPT. TSV‚Äôs are also handy, because they don‚Äôt run into issues when one of the values contains a comma‚Ä¶\nNow it could be that ChatGPT doesn‚Äôt always return the same results and that the table isn‚Äôt exactly as in the AGS 3 .pdf document. This was the case for me:\nCode\ndf1 = pd.read_csv(\"ags3_chatgpt_groups_and_headings.tsv\", sep=\"\\t\")\ndf1[\"df\"] = 1\ndf2 = pd.read_csv(\"ags3_chatgpt_groups_and_headings2.tsv\", sep=\"\\t\")\ndf2[\"df\"] = 2\n\n# Concatenate the two DataFrames\ndf_concat = pd.concat([df1, df2])\n\n# Find the duplicate rows\nmanual_duplicates = df_concat.duplicated(\n    subset=df_concat.columns.difference([\"df\"]), keep=False\n)\n\n# Find the rows that are not duplicates (i.e., the rows that are unique to one DataFrame)\nunique_rows = df_concat[~manual_duplicates]\n\nunique_rows.sort_index()\n\n\n\n\n\n\n\n\n\ngroup_name\ncontents\nparent_group\ndf\n\n\n\n\n32\nHPGI\nHorizontal Profile Gauge Installation Details\nHOLE\n1\n\n\n32\nHPGI\nHorizontal Profile Gauge Installation\nHOLE\n2\n\n\n37\nIFID\nOn Site Volatile Headspace Testing (FID)\nHOLE\n2\n\n\n37\nIFID\nOn Site Volatile Headspace Testing Using Flame...\nHOLE\n1\n\n\n38\nINST\nSingle Point Instrument Installation\nHOLE\n2\n\n\n38\nINST\nSingle Point Instrument Installation Details\nHOLE\n1\n\n\n40\nIPID\nOn Site Volatile Headspace Testing (PID)\nHOLE\n2\n\n\n71\nUNIT\nDefinition of &lt;UNITS&gt; and CNMT_UNIT\n-\n1\n\n\n72\nUNIT\nDefinition of Units\n-\n2"
  },
  {
    "objectID": "sandbox/ags_data_dict_from_pdf_to_json.html#extract-ags-3-and-4-data-dictionaries-from-their-corresponding-ags-.pdf-documents",
    "href": "sandbox/ags_data_dict_from_pdf_to_json.html#extract-ags-3-and-4-data-dictionaries-from-their-corresponding-ags-.pdf-documents",
    "title": "Extract Data from .pdf with ChatGPT",
    "section": "Extract AGS 3 and 4 Data Dictionaries from their corresponding AGS .pdf documents",
    "text": "Extract AGS 3 and 4 Data Dictionaries from their corresponding AGS .pdf documents\n\n\nCode\ndef extract_ags3_data_dict_table(table):\n    headings = []\n    for row in table[2:]:  # Skip first 2 rows: 1st = title, 2nd = headings\n        headings.append(\n            {\n                \"status\": None if row[0] == \"\" else row[0].strip(),\n                \"heading\": row[1].strip(),\n                \"unit\": None if row[2] == \"\" else row[2].strip().replace(\"\\n\", \" \"),\n                \"description\": row[3].strip().replace(\"\\n\", \" \"),\n                \"example\": None if row[4] == \"\" else row[4].strip().replace(\"\\n\", \" \"),\n            }\n        )\n    return headings\n\n\ndef extract_ags4_data_dict_table(table):\n    # Skip rows that don't contain data\n    for i, row in enumerate(table):\n        if \"Suggested\\nUnit / Type\" in row or \"Unit / Type\" in row:\n            first_data_row = i + 1\n            break\n\n    headings = []\n    for row in table[first_data_row:]:\n        row = [x for x in row if x is not None]\n        headings.append(\n            {\n                \"status\": None if row[0] == \"\" else row[0].strip(),\n                \"heading\": row[1].strip(),\n                \"unit\": None if row[2] == \"\" else row[2].strip().replace(\"\\n\", \"\"),\n                \"type\": row[3].strip(),\n                \"description\": row[4].strip().replace(\"\\n\", \" \"),\n                \"example\": None if row[5] == \"\" else row[5].strip().replace(\"\\n\", \" \"),\n            }\n        )\n    return headings\n\n\n\n\nCode\nags_version = 4  # AGS version 3 or 4\npdf_dict = {\n    3: {\"pdf_file\": \"AGS3_v3-1-2005.pdf\", \"from_page\": 22, \"to_page\": 69},\n    4: {\"pdf_file\": \"AGS4-v4-1-1-2022.pdf\", \"from_page\": 18, \"to_page\": 160},\n}\n\n\n\n\nCode\npdf_file, from_page, to_page = pdf_dict[ags_version].values()\n\n# List to store extracted data for each group\nextracted_data = []\nprevious_group_name = \"\"\nwith pdfplumber.open(pdf_file) as pdf:\n    # Adjust the page range based on where the tables are located\n    for page_number in range(from_page, to_page):\n        page = pdf.pages[page_number - 1]  # pdfplumber is 0-based, so subtract 1\n        tables_on_current_page = page.extract_tables()  # Extract tables from the page\n\n        # Iterate through all tables found on the page\n        for table in tables_on_current_page:\n            if ags_version == 3:\n                table_title = table[0][0].strip()  # Get table title from AGS3\n            elif ags_version == 4:\n                table_title = table[0][1].strip()  # Get table title from AGS4\n            print(table_title)\n\n            parts = table_title.split(\": \", 1)  # Split on the first occurrence of ': '\n            if \"Group Name\" in parts[0]:\n                group_name = parts[1].split(\" - \")[0]\n                group_description = \" - \".join(parts[1].split(\" - \")[1:])\n                group_description = group_description.replace(\"\\n\", \" \")\n                if ags_version == 3:\n                    headings = extract_ags3_data_dict_table(table)\n                elif ags_version == 4:\n                    headings = extract_ags4_data_dict_table(table)\n\n                if group_name == previous_group_name:\n                    extracted_data[-1][\"headings\"].extend(headings)\n                else:\n                    extracted_data.append(\n                        {\n                            \"group_name\": group_name,\n                            \"group_description\": group_description,\n                            \"headings\": headings,\n                        }\n                    )\n                previous_group_name = group_name\n\n\nGroup Name: PROJ - Project Information\nGroup Name: ABBR - Abbreviation Definitions\nGroup Name: DICT - User Defined Groups and Headings\nGroup Name: FILE - Associated Files\nGroup Name: TRAN - Data File Transmission Information / Data Status\nGroup Name: TYPE - Definition of Data Types\nGroup Name: UNIT - Definition of Units\nGroup Name: AAVT - Aggregate Abrasion Tests\nGroup Name: AAVT - Aggregate Abrasion Tests\nGroup Name: ACVT - Aggregate Crushing Value Tests\nGroup Name: AELO - Aggregate Elongation Index Tests\nGroup Name: AFLK - Aggregate Flakiness Tests\nGroup Name: AFLK - Aggregate Flakiness Tests\nGroup Name: AIVT - Aggregate Impact Value Tests\nGroup Name: AIVT - Aggregate Impact Value Tests\nGroup Name: ALOS - Los Angeles Abrasion Tests\nGroup Name: ALOS - Los Angeles Abrasion Tests\nGroup Name: APSV - Aggregate Polished Stone Tests\nGroup Name: ARTW - Aggregate Determination of the Resistance to Wear (micro-Deval)\nGroup Name: ASDI - Slake Durability Index Tests\nGroup Name: ASNS - Aggregate Soundness Tests\nGroup Name: AWAD - Aggregate Water Absorption Tests\nGroup Name: AWAD - Aggregate Water Absorption Tests\nGroup Name: BKFL - Exploratory Hole Backfill Details\nGroup Name: CBRG - California Bearing Ratio Tests - General\nGroup Name: CBRT - California Bearing Ratio Tests - Data\nGroup Name: CDIA - Casing Diameter by Depth\nGroup Name: CHIS - Chiselling Details\nGroup Name: CHOC - Chain of Custody Information\nGroup Name: CMPG - Compaction Tests - General\nGroup Name: CMPT - Compaction Tests - Data\nGroup Name: CONG - Consolidation Tests - General\nGroup Name: CONG - Consolidation Tests - General\nGroup Name: CONS - Consolidation Tests - Data\nGroup Name: CONS - Consolidation Tests - Data\nGroup Name: CTRC - Cyclic Triaxial Tests - Consolidation\nGroup Name: CTRC - Cyclic Triaxial Tests - Consolidation\nGroup Name: CTRD - Cyclic Triaxial Tests - Data\nGroup Name: CTRG - Cyclic Triaxial Test - General\nGroup Name: CTRG - Cyclic Triaxial Test - General\nGroup Name: CTRP - Cyclic Triaxial Test - Derived Parameters\nGroup Name: CTRP - Cyclic Triaxial Test - Derived Parameters\nGroup Name: CTRS - Cyclic Triaxial Test - Saturation\nGroup Name: CORE - Coring Information\nGroup Name: DCPG - Dynamic Cone Penetrometer Tests - General\nGroup Name: DCPG - Dynamic Cone Penetrometer Tests - General\nGroup Name: DCPT - Dynamic Cone Penetrometer Tests - Data\nGroup Name: DETL - Stratum Detail Descriptions\nGroup Name: DETL - Stratum Detail Descriptions\nGroup Name: DISC - Discontinuity Data\nGroup Name: DISC - Discontinuity Data\nGroup Name: DLOG - Driller Geological Description\nGroup Name: DOBS - Drilling/Advancement Observations & Parameters\nGroup Name: DOBS - Drilling/Advancement Observations & Parameters\nGroup Name: DPRG - Dynamic Probe Tests - General\nGroup Name: DPRB - Dynamic Probe Tests - Data\nGroup Name: DREM - Depth Related Remarks\nGroup Name: ECTN - Sample Container Details\nGroup Name: ELRG - Environmental Laboratory Reporting\nGroup Name: ELRG - Environmental Laboratory Reporting\nDescription\nDepth to top of test\nspecimen\nLaboratory analytical\nname\n\nGroup Name: ERES - Environmental Contaminant Testing\nGroup Name: ERES - Environmental Contaminant Testing\nGroup Name: ESCG - Effective Stress Consolidation Tests - General\nGroup Name: ESCG - Effective Stress Consolidation Tests - General\nGroup Name: ESCT - Effective Stress Consolidation Tests - Data\nGroup Name: ESCT - Effective Stress Consolidation Tests - Data\nGroup Name: FGHG - Field Geohydraulic Testing - General\nGroup Name: FGHI - Field Geohydraulic Testing - Instrumentation Details\nGroup Name: FGHS - Field Geohydraulic Testing - Test Results (per stage)\nGroup Name: FGHT - Field Geohydraulic Testing - Data\nGroup Name: FLSH - Drilling Flush Details\nGroup Name: FRAC - Fracture Spacing\nGroup Name: FRST - Frost Susceptibility Tests\nGroup Name: FRST - Frost Susceptibility Tests\nGroup Name: GCHM - Geotechnical Chemistry Testing\nGroup Name: GCHM - Geotechnical Chemistry Testing\nGroup Name: GEOL - Field Geological Descriptions\nGroup Name: GRAG - Particle Size Distribution Analysis - General\nGroup Name: GRAG - Particle Size Distribution Analysis - General\nGroup Name: GRAT - Particle Size Distribution Analysis - Data\nGroup Name: GRAT - Particle Size Distribution Analysis - Data\nGroup Name: HDIA - Hole Diameter by Depth\nGroup Name: HDPH - Depth Related Exploratory Hole Information\nGroup Name: HDPH - Depth Related Exploratory Hole Information\nGroup Name: HORN - Exploratory Hole Orientation and Inclination\nGroup Name: ICBR - In Situ California Bearing Ratio Tests\nGroup Name: ICBR - In Situ California Bearing Ratio Tests\nGroup Name: IDEN - In Situ Density Tests\nGroup Name: IFID - On Site Volatile Headspace Testing Using Flame Ionisation Detector\nGroup Name: IPEN - In Situ Hand Penetrometer Tests\nGroup Name: IPID - On Site Volatile Headspace Testing by Photo Ionisation Detector\nGroup Name: IPID - On Site Volatile Headspace Testing by Photo Ionisation Detector\nGroup Name: IPRG - In Situ Permeability Tests - General\nGroup Name: IPRG - In Situ Permeability Tests - General\nGroup Name: IPRT - In Situ Permeability Tests - Data\nGroup Name: IRDX - In Situ Redox Tests\nGroup Name: IRES - In Situ Resistivity Tests\nGroup Name: IRES - In Situ Resistivity Tests\nGroup Name: ISAG - Soakaway Tests - General\nGroup Name: ISAG - Soakaway Tests - General\nGroup Name: ISAT - Soakaway Tests - Data\nGroup Name: ISPT - Standard Penetration Test Results\nGroup Name: ISPT - Standard Penetration Test Results\nGroup Name: IVAN - In Situ Vane Tests\nGroup Name: LBSG - Testing Schedule\nGroup Name: LBST - Testing Schedule Details\nGroup Name: LBST - Testing Schedule Details\nGroup Name: LDEN - Density Tests\nGroup Name: LDEN - Density Tests\nGroup Name: LDYN - Dynamic Testing\nGroup Name: LDYN - Dynamic Testing\nGroup Name: LFCN ‚Äì Laboratory Fall Cone Test\nGroup Name: LFCN ‚Äì Laboratory Fall Cone Test\nGroup Name: LLIN - Linear Shrinkage Tests\nGroup Name: LLIN - Linear Shrinkage Tests\nGroup Name: LLPL - Liquid and Plastic Limit Tests\nGroup Name: LLPL - Liquid and Plastic Limit Tests\nGroup Name: LNMC - Water/moisture Content Tests\nGroup Name: LOCA - Location Details\nGroup Name: LOCA - Location Details\nGroup Name: LPDN - Particle Density Tests\nGroup Name: LPEN - Laboratory Hand Penetrometer Tests\nGroup Name: LRES - Laboratory Resistivity Tests\nGroup Name: LRES - Laboratory Resistivity Tests\nGroup Name: LSLT - Shrinkage Limit Tests\nGroup Name: LSTG - Initial Consumption of Lime Tests - General\nGroup Name: LSTG - Initial Consumption of Lime Tests - General\nGroup Name: LSTT - Initial Consumption of Lime Tests - Data\nGroup Name: LSWL - Swelling Index Testing\nGroup Name: LSWL - Swelling Index Testing\nGroup Name: LTCH - Laboratory Thermal Conductivity\nGroup Name: LTCH - Laboratory Thermal Conductivity\nGroup Name: LUCT - Laboratory Unconfined Compression Test\nGroup Name: LUCT - Laboratory Unconfined Compression Test\nGroup Name: LVAN - Laboratory Vane Tests\nGroup Name: LVAN - Laboratory Vane Tests\nGroup Name: MCVG - MCV Tests - General\nGroup Name: MCVG - MCV Tests - General\nGroup Name: MCVT - MCV Tests - Data\nGroup Name: MCVT - MCV Tests - Data\nGroup Name: MOND - Monitoring Readings\nGroup Name: MONG - Monitoring Installations and Instruments\nGroup Name: MONG - Monitoring Installations and Instruments\nGroup Name: PIPE - Monitoring Installation Pipe Work\nGroup Name: PLTG - Plate Loading Tests - General\nGroup Name: PLTT - Plate Loading Tests - Data\nGroup Name: PMTG - Pressuremeter Test Results - General\nGroup Name: PMTG - Pressuremeter Test Results - General\nGroup Name: PMTD - Pressuremeter Test Data\nGroup Name: PMTL - Pressuremeter Test Results - Individual Loops\nGroup Name: PREM - Project Specific Time Related Remarks\nGroup Name: PTIM - Boring/Drilling Progress by Time\nGroup Name: PTST - Laboratory Permeability Tests\nGroup Name: PTST - Laboratory Permeability Tests\nGroup Name: PTST - Laboratory Permeability Tests\nGroup Name: PUMG - Pumping Tests - General\nGroup Name: PUMT - Pumping Tests - Data\nGroup Name: RCAG - Rock Abrasiveness Tests - General\nGroup Name: RCAG - Rock Abrasiveness Tests - General\nGroup Name: RCAT - Rock Abrasiveness Tests - Data\nGroup Name: RCAT - Rock Abrasiveness Tests - Data\nGroup Name: RCCV - Chalk Crushing Value Tests\nGroup Name: RCCV - Chalk Crushing Value Tests\nGroup Name: RDEN - Rock Porosity and Density Tests\nGroup Name: RDEN - Rock Porosity and Density Tests\nGroup Name: RELD - Relative Density Tests\nGroup Name: RELD - Relative Density Tests\nGroup Name: RESC - Resonant Column Test - Consolidation\nGroup Name: RESC - Resonant Column Test - Consolidation\nGroup Name: RESD - Resonant Column Test ‚Äì Data\nGroup Name: RESD - Resonant Column Test ‚Äì Data\nGroup Name: RESG - Resonant Column Test ‚Äì General\nGroup Name: RESG - Resonant Column Test ‚Äì General\nGroup Name: RESP - Resonant Column Test - Derived Parameters\nGroup Name: RESS - Resonant Column Test ‚Äì Saturation\nGroup Name: RPLT - Point Load Testing\nGroup Name: RPLT - Point Load Testing\nGroup Name: RSCH - Schmidt Rebound Hardness Tests\nGroup Name: RSCH - Schmidt Rebound Hardness Tests\nGroup Name: RSCH - Schmidt Rebound Hardness Tests\nGroup Name: RSHR - Shore Scleroscope Hardness Tests\nGroup Name: RTEN - Tensile Strength Testing\nGroup Name: RUCS - Rock Uniaxial Compressive Strength and Deformability Tests\nGroup Name: RUCS - Rock Uniaxial Compressive Strength and Deformability Tests\nGroup Name: RWCO - Water Content of Rock Tests\nGroup Name: RWCO - Water Content of Rock Tests\nGroup Name: SAMP - Sample Information\nGroup Name: SAMP - Sample Information\nGroup Name: SCDG - Static Cone Dissipation Tests - General\nGroup Name: SCDT - Static Cone Dissipation Tests - Data\nGroup Name: SCDT - Static Cone Dissipation Tests - Data\nGroup Name: SCPG - Static Cone Penetration Tests - General\nGroup Name: SCPP - Static Cone Penetration Tests - Derived Parameters\nGroup Name: SCPT - Static Cone Penetration Tests - Data\nGroup Name: SCPT - Static Cone Penetration Tests - Data\nGroup Name: SHBG - Shear Box Testing - General\nGroup Name: SHBG - Shear Box Testing - General\nGroup Name: SHBT - Shear Box Testing - Data\nGroup Name: SHBT - Shear Box Testing - Data\nGroup Name: STND - Standards / Specifications\nGroup Name: SUCT - Suction Tests\nGroup Name: SUCT - Suction Tests\nGroup Name: TNPC - Ten Per Cent Fines\nGroup Name: TNPC - Ten Per Cent Fines\nGroup Name: TREG - Triaxial Tests - Effective Stress - General\nGroup Name: TRET - Triaxial Tests - Effective Stress - Data\nGroup Name: TRET - Triaxial Tests - Effective Stress - Data\nGroup Name: TREM - Location Specific Time Related Remarks\nGroup Name: TRIG - Triaxial Tests - Total Stress - General\nGroup Name: TRIT - Triaxial Tests - Total Stress - Data\nGroup Name: TRIT - Triaxial Tests - Total Stress - Data\nGroup Name: WADD - Water Added Records\nGroup Name: WADD - Water Added Records\nGroup Name: WETH - Weathering\nGroup Name: WGPG - Wireline Geophysics - General\nGroup Name: WGPT - Wireline Geophysics - Readings\nTool\nCalliper X-Y (2 x two\narm Calliper)\nDownhole Magnetic\nResonance\n\nGroup Name: WINS - Window or Windowless Sampling Run Details\nGroup Name: WSTG - Water Strike - General\nGroup Name: WSTD - Water Strike - Details\n\n\n\n\nCode\nwith open(f\"ags{ags_version}_manual_groups.json\", \"r\") as f:\n    manual_groups = json.load(f)\n\nextracted_groups = [d[\"group_name\"] for d in extracted_data]\n\nprint(set(manual_groups) - set(extracted_groups))\nprint(set(extracted_groups) - set(manual_groups))\n\n\n{'LFCN'}\n{'LFCN ‚Äì Laboratory Fall Cone Test'}\n\n\n\n\nCode\n# Save the extracted data to a JSON file\nwith open(f\"ags{ags_version}_data_dict_p{from_page}-{to_page}.json\", \"w\") as json_file:\n    json.dump(extracted_data, json_file, indent=2)"
  }
]